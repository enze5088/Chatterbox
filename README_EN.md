# Chatterbox
Chinese language model based on BloomZ-1b2. After cutting the thesaurus and WordsEmbedding, the parameter quantity is about 0.9B, and the training is conducted with open source data. And build Web chat Demo and wechat robot.


## Datasets
Currently, we mainly use fine-tuning Belle, alpaca_gpt4_data_zh, firefly. And organize the currently available training datasets, with over 30 datasets currently organized. 


Detailed datasets collection and organization can be found [here](./docs/datasets.md).



## License

The use of this repo is subject to the [Apache License](https://github.com/enze5088/Chatterbox/blob/main/LICENSE)
